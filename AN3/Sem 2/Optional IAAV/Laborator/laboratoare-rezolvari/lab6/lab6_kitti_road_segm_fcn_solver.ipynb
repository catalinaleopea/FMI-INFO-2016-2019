{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab6_kitti_road_segm_fcn_solver.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vWC9X_-tS0l4","colab_type":"text"},"cell_type":"markdown","source":["# Laborator 6 - Segmentare Semantică\n","\n","În acest laborator veți construi și antrena o rețea complet convoluțională (***FCN - Fully Convolutional Network***), al cărei rezultat este o imagine (nu doar o clasificare). Veți implementa trei tehnici speciale: ***convoluții 1x1***, ***upsampling*** și ***skip layers*** pentru a vă antrena propriul FCN.\n","\n","Veți începe de la un model pre-antrenat pe ImageNet (***VGG16***). După eliminarea straturilor de clasificare (fully connected layers), veți putea adăuga cele trei tehnici (conv. 1x1, upsampling și skip layers) pentru a obține un FCN capabil să clasifice fiecare pixel din imagine.\n","\n","Veți construi o rețea de segmentare semantică pentru a identifica spațiul liber pe drum (veți folosi setul de date [Kitti Road](http://www.cvlibs.net/datasets/kitti/eval_road.php)).\n","\n","## De ce FCN?\n","\n","O rețea convoluțională normală constă dintr-o serie de straturi convoluționale, urmată de straturi fully connected și, în cele din urmă, de o funcție de activare Softmax. Aceasta este o arhitectură bună pentru clasificare, însă straturile fully connected nu păstrează informația spațială. FCN păstrează informația spațială în întreaga rețea (FCN funcționează cu imagini de orice dimensiune).\n","\n","Din punct de vedere structural, FCN este compusă din două părți: encoder (VGG, ResNet - extrage caracteristici din imagine) și decoder (mărește outputul encoderului pentru a fi de aceeași dimensiune ca imaginea originală; astfel, se realizează clasificarea fiecărui pixel individual din imaginea originală)\n","\n","---\n","\n","![alt text](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/05d20ad124a8696f387e6c9632dec0b31251df64/4-Figure3-1.png)"]},{"metadata":{"id":"fI2DlmjZDyAR","colab_type":"code","cellView":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":383},"outputId":"ef799b0b-525c-4d40-b561-4f3fbaf8496e","executionInfo":{"status":"error","timestamp":1556051601048,"user_tz":-180,"elapsed":22127,"user":{"displayName":"Catalina","photoUrl":"https://lh4.googleusercontent.com/-fP71obuQvas/AAAAAAAAAAI/AAAAAAAAAjY/POu2EDachbA/s64/photo.jpg","userId":"06274544867360005378"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","print(\"OK\")"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-09927a6d-8244-414f-a641-ca0e56df5e5b\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-09927a6d-8244-414f-a641-ca0e56df5e5b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ad6d6631f908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"rHMvCqvAFqCy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Install dependencies\n","!apt-get update\n","!apt-get install ffmpeg\n","!pip install moviepy tqdm\n","\n","# Download & Extract the Kitti Road dataset\n","!mkdir ./data ./runs ./saved_models\n","!wget --progress=bar:force http://kitti.is.tue.mpg.de/kitti/data_road.zip -P ./data\n","!unzip ./data/data_road.zip -d ./data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"08wPydwvFiWZ","colab_type":"code","colab":{}},"cell_type":"code","source":["import os.path\n","import tensorflow as tf\n","import helper\n","import warnings\n","from distutils.version import LooseVersion\n","import project_tests as tests\n","\n","from moviepy.editor import VideoFileClip\n","import scipy.misc\n","import numpy as np\n","\n","import sys\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","import glob\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oCm2peGHA8x0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Descărcați modelul VGG pre-antrenat\n","\n","num_classes = 2\n","image_shape = (160, 576)\n","data_dir = './data'\n","runs_dir = './runs'\n","\n","helper.maybe_download_pretrained_vgg(data_dir)\n","tests.test_for_kitti_dataset(data_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5fxnI7Fnr8TH","colab_type":"text"},"cell_type":"markdown","source":["### Vizualizare dataset Kitti Road"]},{"metadata":{"id":"c94nEukbr2xT","colab_type":"code","colab":{}},"cell_type":"code","source":["num_samples = 5\n","get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n","\n","plt.figure(figsize=(10, 10))\n","\n","for batch, (images, labels) in enumerate(get_batches_fn(num_samples)):\n","  for i, (image, label) in enumerate(zip(images, labels)):\n","    plt.subplot(num_samples, 2, 2*i+1)\n","    plt.axis('off')\n","    plt.imshow(image, None)\n","    plt.subplot(num_samples, 2, 2*i+2)\n","    plt.axis('off')\n","    plt.imshow(label[:,:,0], 'jet')\n","    \n","  break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UbYlXAZMFmuz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Check TensorFlow Version\n","assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n","print('TensorFlow Version: {}'.format(tf.__version__))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G0elY8-KGWX7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Check for a GPU\n","if not tf.test.gpu_device_name():\n","    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n","else:\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P7uOFiTcq_np","colab_type":"text"},"cell_type":"markdown","source":["## Cerința 1 - Încărcați în Tensorflow modelul VGG pre-antrenat și obțineți tensorii corespunzători layerelor image_input, pool3, pool4, conv_7, precum și keep_prob (pentru dropout în timpul procesului de fine-tuning)\n","\n","* Folosiți [`tf.saved_model.loader.load`](https://www.tensorflow.org/api_docs/python/tf/saved_model/loader/load) pentru a încărca modelul și parametrii\n","* Folosiți [`graph.get_tensor_by_name`](https://www.tensorflow.org/api_docs/python/tf/Graph) pentru a obține tensorii din modelul VGG\n","\n","![alt text](https://csdl-images.computer.org/trans/tp/2017/04/figures/shelh3-2572683.gif)\n"]},{"metadata":{"id":"FaKNLnaZGeqL","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_vgg(sess, vgg_path):\n","    \"\"\"\n","    Încărcați în Tensorflow modelul VGG pre-antrenat\n","    :param sess: Sesiunea Tensorflow\n","    :param vgg_path: Calea către directorul vgg, conținând \"variables/\" și \"saved_model.pb\"\n","    :return: Tuplu de Tensori din modelul VGG (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n","    \"\"\"\n","    # TODO:\n","    # Folosiți tf.saved_model.loader.load pentru a încărca modelul și parametrii\n","    vgg_tag = 'vgg16'\n","\n","    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n","\n","    vgg_input_tensor_name = 'image_input:0'\n","    vgg_keep_prob_tensor_name = 'keep_prob:0'\n","    vgg_layer3_out_tensor_name = 'layer3_out:0'\n","    vgg_layer4_out_tensor_name = 'layer4_out:0'\n","    vgg_layer7_out_tensor_name = 'layer7_out:0'\n","\n","    graph = tf.get_default_graph()\n","    w1 = graph.get_tensor_by_name(vgg_input_tensor_name)\n","    kp = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n","    w3 = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n","    w4 = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n","    w7 = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n","\n","    return w1, kp, w3, w4, w7"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ciWk3n1fGh5y","colab_type":"code","colab":{}},"cell_type":"code","source":["tests.test_load_vgg(load_vgg, tf)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D8gNhGmVtF20","colab_type":"text"},"cell_type":"markdown","source":["## Cerința 2 - Adăugați layerele corespunzătoare decoderului. Construiți skip-layers folosind layerele vgg\n","\n","* pentru a evita problema exploziei gradienților, folosiți [***`tf.multiply`***](https://www.tensorflow.org/api_docs/python/tf/multiply) pentru a scala rezultatul layerelor de pooling 3 și 4 înainte de a aplica convoluțiile 1x1 (folosiți `0.0001` pentru pool_3 și `0.01` pentru pool_4)\n","* folosiți [***`tf.layers.conv2d`***](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d) pentru a adăuga convoluțiile 1x1, pentru a reduce depth-ul layerelor la numărul de clase\n","* folosiți [***`tf.layers.conv2d_transpose`***](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d_transpose) pentru a mări rezoluția layerelor (2x pentru conv_7, 2x pentru primul skip-layer (între pool_4 și conv_7 upscaled) și 8x pentru cel de-al 2-lea skip layer (între pool_3 și primul skip-layer upscaled))\n","* folosiți [***`tf.add`***](https://www.tensorflow.org/api_docs/python/tf/add) pentru skip-layers\n","\n","***Hint: Folosiți regularizare L2 pentru a preveni overfitting-ul ([`tf.contrib.layers.l2_regularizer`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/l2_regularizer))***"]},{"metadata":{"id":"S08OD8kJGkVT","colab_type":"code","colab":{}},"cell_type":"code","source":["def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n","    \"\"\"\n","    Creați layerele pentru FCN; construiți skip-layers folosind layerele vgg\n","    :param vgg_layer3_out: Tensor pentru layerul 3\n","    :param vgg_layer4_out: Tensor pentru layerul 4\n","    :param vgg_layer7_out: Tensor pentru layerul 7\n","    :param num_classes: Numărul de clase\n","    :return: Tensorul pentru layerul de output\n","    \"\"\"\n","    \n","    # The outputs of pooling layers 3 and 4 are scaled before they are fed\n","    # into the 1x1 convolutions\n","    vgg_layer3_out_scaled = tf.multiply(vgg_layer3_out, 0.0001)\n","    conv_1x1_lay3 = tf.layers.conv2d(inputs=vgg_layer3_out_scaled,\n","                                     filters=num_classes,\n","                                     kernel_size=(1, 1),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     kernel_initializer=tf.truncated_normal_initializer(stddev=1e-3),\n","                                     kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n","\n","    vgg_layer4_out_scaled = tf.multiply(vgg_layer4_out, 0.01)\n","    conv_1x1_lay4 = tf.layers.conv2d(inputs=vgg_layer4_out_scaled,\n","                                     filters=num_classes,\n","                                     kernel_size=(1, 1),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     kernel_initializer=tf.truncated_normal_initializer(stddev=1e-3),\n","                                     kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n","\n","    conv_1x1_lay7 = tf.layers.conv2d(inputs=vgg_layer7_out,\n","                                     filters=num_classes,\n","                                     kernel_size=(1, 1),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     kernel_initializer=tf.truncated_normal_initializer(stddev=1e-3),\n","                                     kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n","\n","    # scale up by x2\n","    output = tf.layers.conv2d_transpose(inputs=conv_1x1_lay7,\n","                                        filters=num_classes,\n","                                        kernel_size=(4, 4),\n","                                        strides=(2, 2),\n","                                        padding='same',\n","                                        kernel_initializer=tf.truncated_normal_initializer(stddev=1e-2),\n","                                        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n","\n","    # first skip layer\n","    output = tf.add(output, conv_1x1_lay4)\n","\n","    # scale up by x2\n","    output = tf.layers.conv2d_transpose(inputs=output,\n","                                        filters=num_classes,\n","                                        kernel_size=(4, 4),\n","                                        strides=(2, 2),\n","                                        padding='same',\n","                                        kernel_initializer=tf.truncated_normal_initializer(stddev=1e-2),\n","                                        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n","\n","    # second skip layer\n","    output = tf.add(output, conv_1x1_lay3)\n","\n","    # scaled up by x8 to get original image size\n","    output = tf.layers.conv2d_transpose(inputs=output,\n","                                        filters=num_classes,\n","                                        kernel_size=(16, 16),\n","                                        strides=(8, 8),\n","                                        padding='same',\n","                                        kernel_initializer=tf.truncated_normal_initializer(stddev=1e-2),\n","                                        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n","\n","    return output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"szLhOEreGqMk","colab_type":"code","colab":{}},"cell_type":"code","source":["tests.test_layers(layers)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wSqF_zcv5A4R","colab_type":"text"},"cell_type":"markdown","source":["## Cerința 3 - Adăugați operațiile de loss și optimizare\n","\n","* folosiți [***`tf.nn.softmax_cross_entropy_with_logits`***](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) ca funcție de loss\n","* folosiți [***`tf.train.AdamOptimizer`***](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) ca optimizator\n","\n","***Hint: ***\n"," * ***trebuie să însumați loss-ul de regularizare cu loss-ul cross-entropy pentru ca regularizarea să aibă loc (folosiți [`tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES`)](https://www.tensorflow.org/api_docs/python/tf/get_collection) pentru a obține loss-ul de regularizare)***\n"," * *** `nn_last_layer` și `correct_label` trebuie redimensionați pentru a deveni 2D (fiecare rând va reprezenta un pixel, iar fiecare coloană va reprezenta o clasă)***"]},{"metadata":{"id":"CUcj5y_FGsWq","colab_type":"code","colab":{}},"cell_type":"code","source":["def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n","    \"\"\"\n","    Adăugați operațiile de loss și optimizare\n","    :param nn_last_layer: Tensor pentru ultimul layer din rețea\n","    :param correct_label: Placeholder pentru imaginea ground-truth (imaginea label/mască)\n","    :param learning_rate: Placeholder pentru learning rate\n","    :param num_classes: Numărul de clase\n","    :return: (logits, optimizer, cross_entropy_loss)\n","    \"\"\"\n","    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n","    correct_label = tf.reshape(correct_label, (-1, num_classes))\n","\n","    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n","                                                                                labels=correct_label))\n","\n","    # compute the regularization loss\n","    try:\n","        regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n","        regularization_loss = tf.add_n(regularization_losses)\n","\n","        # compute the total loss\n","        total_loss = tf.add(cross_entropy_loss, regularization_loss)\n","    except:\n","        total_loss = cross_entropy_loss\n","\n","    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n","\n","    return logits, optimizer, total_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EHkGpLTrGwsa","colab_type":"code","colab":{}},"cell_type":"code","source":["tests.test_optimize(optimize)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"enz8BOiI-C1h","colab_type":"text"},"cell_type":"markdown","source":["## Cerința 4 - Antrenați rețeaua și afișați loss-ul în timpul antrenării\n","* folosiți `0.5` pentru dropout\n","* folosiți `1e-4` pentru learning rate"]},{"metadata":{"id":"ZZNBsvKRGzSs","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n","             correct_label, keep_prob, learning_rate):\n","    \"\"\"\n","    Antrenați rețeaua și afișați loss-ul în timpul antrenării\n","    :param sess: Sesiunea Tensorflow\n","    :param epochs: Numărul de epoci\n","    :param batch_size: Dimensiunea batch-ului de imagini\n","    :param get_batches_fn: Funcție pentru a obține batch-uri de imagini. Apelați folosind get_batches_fn(batch_size)\n","    :param train_op: Operație Tensorflow pentru a antrena rețeaua neurală\n","    :param cross_entropy_loss: Tensor pentru loss\n","    :param input_image: Placeholder pentru imagini\n","    :param correct_label: Placeholder pentru labeluri\n","    :param keep_prob: Placeholder pentru dropout\n","    :param learning_rate: Placeholder pentru learning rate\n","    \"\"\"\n","    # TODO: Implement function\n","    for epoch in range(epochs):\n","        for batch, (image, label) in enumerate(get_batches_fn(batch_size)):\n","            feed_dict = {input_image: image, correct_label: label, keep_prob: 0.5, learning_rate: 1e-4}\n","            _, loss = sess.run([train_op, cross_entropy_loss], feed_dict=feed_dict)\n","            print('Epoch {} Batch {} Loss {}'.format(epoch, batch, loss), flush=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fcQ4QBwG_Ymu","colab_type":"text"},"cell_type":"markdown","source":["## BONUS 1 - Aplicați rețeaua neurală pe un video\n","\n","Metoda `process_image` primește un frame RGB, aplică rețeaua neurală pentru a segmenta drumul (obține o mască), aplică masca peste imaginea originală și o întoarce la output."]},{"metadata":{"id":"uEGOZyY2G5Vq","colab_type":"code","colab":{}},"cell_type":"code","source":["def process_image(image):\n","    \"\"\"\n","    Aplică rețeaua neurală unui frame dintr-un video pentru a segmenta drumul\n","    : param image: Frame RGB\n","    : return: Imagine RGB cu masca drumului aplicată\n","    \"\"\"\n","    # resize the image\n","    orig_image_shape = image.shape[:2]\n","    image = scipy.misc.imresize(image, image_shape)\n","\n","    net_output = sess.run([tf.nn.softmax(logits)],\n","            {keep_prob: 1.0, input_image: [image]})\n","\n","    label_idx = np.argmax(net_output, axis=2)\n","\n","    value_fill = label_idx.copy()\n","    value_fill.fill(1)\n","\n","    segmentation = np.equal(label_idx, value_fill).reshape(image_shape[0], image_shape[1], 1)\n","    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n","\n","    image = scipy.misc.imresize(image, orig_image_shape)\n","    mask = scipy.misc.imresize(mask, orig_image_shape)\n","\n","    road_im = scipy.misc.toimage(image)\n","    mask = scipy.misc.toimage(mask, mode='RGBA')\n","    road_im.paste(mask, box=None, mask=mask)\n","\n","    return np.array(road_im)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jLWWz0gMFPWK","colab_type":"code","colab":{}},"cell_type":"code","source":["train_model = True\n","process_video = False\n","load_model = False\n","save_model = True\n","output_dir = None\n","\n","# process image parameters\n","sess = tf.Session()\n","keep_prob = tf.placeholder(tf.float32)\n","loggits = tf.placeholder(tf.int32, [None, None, None, 2])\n","input_image = tf.placeholder(tf.int32, [None, None, 3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"52EtJ2ANG8Z3","colab_type":"code","colab":{}},"cell_type":"code","source":["def run():\n","    global image_shape, logits, sess, keep_prob, input_image, output_dir\n","\n","    tf.reset_default_graph()\n","    \n","    with tf.Session() as sess:\n","        # Path to vgg model\n","        vgg_path = os.path.join(data_dir, 'vgg')\n","        # Create function to get batches\n","        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n","        \n","        # TODO: Construiți rețeaua apelând metodele load_vgg, layers și optimize\n","        epochs = 30\n","        batch_size = 8\n","        learning_rate = tf.placeholder(tf.float32)\n","        correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes])\n","\n","        input_image, keep_prob, layer3_out, layer4_out, layer7_out = load_vgg(sess, vgg_path)\n","        layer_output = layers(layer3_out, layer4_out, layer7_out, num_classes)\n","        logits, optimizer, total_loss = optimize(layer_output, correct_label, learning_rate, num_classes)\n","\n","        # TODO: Antrenați rețeaua apelând metoda train_nn\n","        saver = tf.train.Saver()\n","        sess.run(tf.global_variables_initializer())\n","\n","        if load_model:\n","            checkpoint = tf.train.get_checkpoint_state('./saved_models')\n","            try:\n","                saver.restore(sess, checkpoint.model_checkpoint_path)\n","                print('Successfully loaded {}'.format(checkpoint.model_checkpoint_path))\n","            except:\n","                print('Could not find network weights')\n","\n","        if train_model:\n","            train_nn(sess, epochs, batch_size, get_batches_fn, optimizer, total_loss, input_image,\n","                     correct_label, keep_prob, learning_rate)\n","\n","        # Salvează imaginile de output folosind helper.save_inference_samples\n","        output_dir = helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n","        \n","        if save_model:\n","            saver.save(sess, './saved_models/model')\n","\n","        # BONUS 1 - Aplicați rețeaua pe un video\n","        if process_video:\n","            out_video = './videos/street_drive_road_segm.mp4'\n","            in_video = './videos/street_drive.mp4'\n","\n","            clip = VideoFileClip(in_video)\n","            video_clip = clip.fl_image(process_image)\n","            video_clip.write_videofile(out_video, audio=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pu1rovDwQJJ5","colab_type":"code","colab":{}},"cell_type":"code","source":["run()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HkEok8EDIMec","colab_type":"text"},"cell_type":"markdown","source":["### Vizualizare output"]},{"metadata":{"id":"uikGW-rlKij0","colab_type":"code","colab":{}},"cell_type":"code","source":["if output_dir:\n","  num_samples = 10\n","  image_list = glob.glob(os.path.join(output_dir, '*.png'))\n","  img_height, img_width = image_shape\n","\n","  samples = random.sample(image_list, num_samples)\n","\n","  plt.figure(figsize=(10, 30))\n","\n","  for i, sample in enumerate(samples):\n","    img = mpimg.imread(sample)\n","    plt.subplot(num_samples, 1, i+1)\n","    plt.axis('off')\n","    plt.imshow(img, None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-10Z1CnVCG3V","colab_type":"text"},"cell_type":"markdown","source":["## BONUS 2 - Augmentați imaginile pentru rezultate mai bune \n"," * [how-to-prepare-augment-images-for-neural-network](https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network)\n"," \n","## BONUS 3 - Antrenați rețeaua pe setul de date [cityscapes](https://www.cityscapes-dataset.com/)\n"]}]}